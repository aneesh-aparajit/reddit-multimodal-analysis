{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4743fc6",
   "metadata": {},
   "source": [
    "# Multimodal Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef533908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: aneesh-aparajit\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from colorama import Back, Fore, Style\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import AUROC, Accuracy, F1Score, Precision, Recall\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "c_ = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -a \"aneesh-aparajit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de962b32",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f726c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 101\n",
    "    debug = False  # set debug=False for Full Training\n",
    "    exp_name = \"vit/sbert\"\n",
    "    model_name = \"vit-sbert-multimodal\"\n",
    "    backbone = \"google/vit-base-patch16-224+sentence-transformers/all-mpnet-base-v2\"\n",
    "    tokenizer = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    image_encoder = \"google/vit-base-patch16-224\"\n",
    "    train_bs = 24\n",
    "    valid_bs = 48\n",
    "    img_size = [224, 224]\n",
    "    max_len = 128\n",
    "    epochs = 50\n",
    "    competition = \"memotions-7k\"\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer     = 'Adam'\n",
    "    learning_rate = 3e-4\n",
    "    rho           = 0.9\n",
    "    eps           = 1e-6\n",
    "    lr_decay      = 0\n",
    "    betas         = (0.9, 0.999)\n",
    "    momentum      = 0\n",
    "    alpha         = 0.99\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    weight_decay  = 1e-6\n",
    "\n",
    "    # Config\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    num_folds     = 5\n",
    "    num_classes   = 3\n",
    "\n",
    "    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66169d0",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88195b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SEEDED <<<\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(\">>> SEEDED <<<\")\n",
    "\n",
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fd444",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "## Get Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b26693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model: nn.Module):\n",
    "    \"\"\"\n",
    "    Returns the optimizer based on the Config files.\n",
    "    \"\"\"\n",
    "    if Config.optimizer == \"Adadelta\":\n",
    "        optimizer = optim.Adadelta(\n",
    "            model.parameters(), lr=Config.learning_rate, rho=Config.rho, eps=Config.eps\n",
    "        )\n",
    "    elif Config.optimizer == \"Adagrad\":\n",
    "        optimizer = optim.Adagrad(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            lr_decay=Config.lr_decay,\n",
    "            weight_decay=Config.weight_decay,\n",
    "        )\n",
    "    elif Config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            betas=Config.betas,\n",
    "            eps=Config.eps,\n",
    "        )\n",
    "    elif Config.optimizer == \"RMSProp\":\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            alpha=Config.alpha,\n",
    "            eps=Config.eps,\n",
    "            weight_decay=Config.weight_decay,\n",
    "            momentum=Config.momentum,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"The optimizer {Config.optimizer} has not been implemented.\"\n",
    "        )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e084f3",
   "metadata": {},
   "source": [
    "## Get Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f901876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer: optim):\n",
    "    \"\"\"\n",
    "    A method which returns the required schedulers.\n",
    "        - Extracted from Awsaf's Kaggle.\n",
    "    \"\"\"\n",
    "    if Config.scheduler == \"CosineAnnealingLR\":\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer=optimizer, T_max=Config.T_max, eta_min=Config.min_lr\n",
    "        )\n",
    "    elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer=optimizer, T_0=Config.T_0, eta_min=Config.eta_min\n",
    "        )\n",
    "    elif Config.scheduler == \"ReduceLROnPlateau\":\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=0.1,\n",
    "            patience=10,\n",
    "            threshold=0.0001,\n",
    "            min_lr=Config.min_lr,\n",
    "        )\n",
    "    elif Config.scheduler == \"ExponentialLR\":\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.85)\n",
    "    elif Config.scheduler is None:\n",
    "        scheduler = None\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"The Scheduler you have asked has not been implemented\"\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a02ea",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Create Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80a7bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds():\n",
    "    df = pd.read_csv('../memotion_dataset_7k/labels.csv')\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df['label'] = df['offensive']\n",
    "    df['label'] = np.where(df['label'] == 'hateful_offensive', 'very_offensive', df['label'])\n",
    "    \n",
    "    mskf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    df['kfold'] = -1\n",
    "    for fold, (train, valid) in enumerate(mskf.split(X=df, y=df['label'])):\n",
    "        df.loc[valid, 'kfold'] = fold\n",
    "    \n",
    "    df['label'] = df['label'].map({\n",
    "        'not_offensive': 0, \n",
    "        'slight': 1, \n",
    "        'very_offensive': 2\n",
    "    })\n",
    "\n",
    "    df.to_csv('../memotion_dataset_7k/folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c00d8",
   "metadata": {},
   "source": [
    "## Sample Images\n",
    "![memes](../resources/memes-preview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3977ce",
   "metadata": {},
   "source": [
    "## Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9697e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemotionDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(Config.tokenizer)\n",
    "        self.transforms = A.Compose([\n",
    "            A.Resize(height=Config.img_size[0], width=Config.img_size[1]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, ix: int) -> Dict[str, torch.Tensor]:\n",
    "        row = self.df.iloc[ix]\n",
    "\n",
    "        # Image\n",
    "        image_path = os.path.join('../memotion_dataset_7k/images', row['image_name'].lower())\n",
    "        img = np.array(Image.open(image_path).convert('RGB'))\n",
    "        img = self.transforms(image=img)['image']\n",
    "\n",
    "        # Text\n",
    "        text = row['text_corrected'].lower()\n",
    "        out = self.tokenizer(\n",
    "            text=text, \n",
    "            max_length=Config.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # __import__('pprint').pprint(out)\n",
    "\n",
    "        return  {\n",
    "            'image': img, \n",
    "            'input_ids': out['input_ids'].squeeze(),\n",
    "            'attention_mask': out['attention_mask'].squeeze(),\n",
    "            'label': torch.LongTensor([row['label']]).squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b429acc",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b97f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = AutoModel.from_pretrained(Config.image_encoder)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encoder.forward(x)[\"pooler_output\"]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e69820",
   "metadata": {},
   "source": [
    "## Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db110fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = AutoModel.from_pretrained(Config.tokenizer)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        x = self.encoder.forward(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return x[\"pooler_output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3941e",
   "metadata": {},
   "source": [
    "## Memotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98ebfe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "class MemotionModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.alpha_img = torch.randn(size=(1,), requires_grad=True)\n",
    "        self.alpha_txt = torch.randn(size=(1,), requires_grad=True)\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(\n",
    "        self, image: torch.Tensor, input_ids: torch.Tensor, attention_mask: torch.Tensor, label: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        img_out = self.image_encoder.forward(image)\n",
    "        txt_out = self.text_encoder.forward(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        wt_emb = self.alpha_txt * txt_out + self.alpha_img * img_out\n",
    "        x = self.fc1(self.dropout(wt_emb))\n",
    "        x = self.fc2(self.dropout(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693f08c",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Training One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0e695eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim,\n",
    "    dataloader: DataLoader,\n",
    "    scheduler=None,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    precision_metric = Precision(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    recall_metric = Recall(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    auroc_metric = AUROC(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    f1_metrics = F1Score(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"(train) \")\n",
    "    for step, batch in pbar:\n",
    "        batch = {k: v.to(Config.device) for k, v in batch.items()}\n",
    "        labels = batch[\"label\"]\n",
    "        yHat = model.forward(**batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(yHat, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.shape[0]\n",
    "        dataset_size += labels.shape[0]\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        out = torch.argmax(yHat, axis=1)\n",
    "        accuracy = accuracy_metric(out, labels)\n",
    "        precision = precision_metric(out, labels)\n",
    "        recall = recall_metric(out, labels)\n",
    "        auroc = auroc_metric(F.softmax(yHat, dim=1), labels)\n",
    "        f1 = f1_metrics(yHat, labels)\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train/loss\": epoch_loss,\n",
    "                \"train/accuracy\": accuracy,\n",
    "                \"train/precision\": precision,\n",
    "                \"train/recall\": recall,\n",
    "                \"train/auroc\": auroc,\n",
    "                \"train/f1\": f1,\n",
    "                \"train/current_lr\": current_lr,\n",
    "            },\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "        pbar.set_postfix(epoch_loss=f\"{epoch_loss:.5f}\", current_lr=f\"{current_lr:.5f}\")\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2346e28",
   "metadata": {},
   "source": [
    "## Validating One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dd24b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "    model: nn.Module, dataloader: DataLoader\n",
    ") -> Tuple[float, dict]:\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    precision_metric = Precision(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    recall_metric = Recall(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    auroc_metric = AUROC(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    f1_metrics = F1Score(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "\n",
    "    val_scores = defaultdict(list)\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"(valid) \")\n",
    "    for step, batch in pbar:\n",
    "        batch = {k: v.to(Config.device) for k, v in batch.items()}\n",
    "        labels = batch[\"label\"]\n",
    "        yHat = model.forward(**batch)\n",
    "\n",
    "        loss = criterion(yHat, labels)\n",
    "\n",
    "        running_loss += loss.item() * labels.shape[0]\n",
    "        dataset_size += labels.shape[0]\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        out = torch.argmax(yHat, axis=1)\n",
    "        accuracy = accuracy_metric(out, labels)\n",
    "        precision = precision_metric(out, labels)\n",
    "        recall = recall_metric(out, labels)\n",
    "        auroc = auroc_metric(F.softmax(yHat, dim=1), labels)\n",
    "        f1 = f1_metrics(yHat, labels)\n",
    "\n",
    "        val_scores[\"accuracy\"].append(accuracy)\n",
    "        val_scores[\"precision\"].append(precision)\n",
    "        val_scores[\"recall\"].append(recall)\n",
    "        val_scores[\"auroc\"].append(auroc)\n",
    "        val_scores[\"f1\"].append(f1)\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"valid/loss\": epoch_loss,\n",
    "                \"valid/accuracy\": accuracy,\n",
    "                \"valid/precision\": precision,\n",
    "                \"valid/recall\": recall,\n",
    "                \"valid/auroc\": auroc,\n",
    "                \"valid/f1\": f1,\n",
    "            },\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "    return epoch_loss, val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7615a67",
   "metadata": {},
   "source": [
    "## Train one Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c48a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim,\n",
    "    trainloader: DataLoader,\n",
    "    validloader: DataLoader,\n",
    "    run: wandb,\n",
    "    fold: int,\n",
    "    scheduler: lr_scheduler = None,\n",
    ") -> Tuple[nn.Module, defaultdict]:\n",
    "    wandb.watch(models=[model], log_freq=100)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "    best_epoch = -1\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "        gc.collect()\n",
    "        print(f\"\\t\\t\\t\\t########## EPOCH [{epoch+1}/{Config.epochs}] ##########\")\n",
    "        train_loss = train_one_epoch(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            dataloader=trainloader,\n",
    "        )\n",
    "        valid_loss, valid_scores = validate_one_epoch(\n",
    "            model=model, dataloader=validloader\n",
    "        )\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train/epoch/loss\": train_loss,\n",
    "                \"valid/epoch/loss\": valid_loss,\n",
    "                \"valid/epoch/accuracy\": np.mean(valid_scores[\"accuracy\"]),\n",
    "                \"valid/epoch/precision\": np.mean(valid_scores[\"precision\"]),\n",
    "                \"valid/epoch/recall\": np.mean(valid_scores[\"recall\"]),\n",
    "                \"valid/epoch/auroc\": np.mean(valid_scores[\"auroc\"]),\n",
    "                \"valid/epoch/f1\": np.mean(valid_scores[\"f1\"]),\n",
    "                \"current_lr\": optimizer.param_groups[0][\"lr\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        history[\"accuracy\"].append(np.mean(valid_scores[\"accuracy\"]))\n",
    "        history[\"precision\"].append(np.mean(valid_scores[\"precision\"]))\n",
    "        history[\"recall\"].append(np.mean(valid_scores[\"recall\"]))\n",
    "        history[\"auroc\"].append(np.mean(valid_scores[\"auroc\"]))\n",
    "        history[\"f1\"].append(np.mean(valid_scores[\"f1\"]))\n",
    "\n",
    "        print(\n",
    "            f'Valid Accuracy: {np.mean(valid_scores[\"accuracy\"]):.5f} | Valid Loss: {valid_loss:.5f}'\n",
    "        )\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            print(\n",
    "                f\"{c_}Validation Score Improved from {best_loss:.5f} to {valid_loss:.5f}\"\n",
    "            )\n",
    "            best_epoch = epoch + 1\n",
    "            best_loss = valid_loss\n",
    "            run.summary[\"Best Loss\"] = best_loss\n",
    "            run.summary[\"Best Epoch\"] = best_epoch\n",
    "            run.summary[\"Best Accuracy\"] = np.mean(valid_scores[\"accuracy\"])\n",
    "            run.summary[\"Best Precision\"] = np.mean(valid_scores[\"precision\"])\n",
    "            run.summary[\"Best Recall\"] = np.mean(valid_scores[\"recall\"])\n",
    "            run.summary[\"Best AUROC\"] = np.mean(valid_scores[\"auroc\"])\n",
    "            run.summary[\"Best F1 Score\"] = np.mean(valid_scores[\"f1\"])\n",
    "\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"../artifacts/models/best/best_epoch-{fold:02d}.bin\"\n",
    "            torch.save(obj=best_model_wts, f=PATH)\n",
    "            wandb.save(PATH)\n",
    "            print(f\"MODEL SAVED!{sr_}\")\n",
    "\n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"../artifacts/models/last/last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(last_model_wts, PATH)\n",
    "\n",
    "    model.load_state_dict(best_model_wts, strict=True)\n",
    "    torch.save(history, f=f\"../artifacts/history/fold-{fold:02d}.pth\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac1892",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf0c06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_4112.jpg</td>\n",
       "      <td>YOU HAVE NEVER SEEN TITANIC?!? RU SRS? quickme...</td>\n",
       "      <td>YOU HAVE NEVER SEEN TITANIC?!? R U SRS? quickm...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>slight</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_3710.jpg</td>\n",
       "      <td>SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...</td>\n",
       "      <td>SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_3739.jpg</td>\n",
       "      <td>spiderman homecoming looks amazing</td>\n",
       "      <td>spiderman homecoming looks amazing</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_62.jpg</td>\n",
       "      <td>THANOS GETS ALL INFINITY STONES AT THE END OF ...</td>\n",
       "      <td>THANOS GETS ALL INFINITY STONES AT THE END OF ...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_5891.jpg</td>\n",
       "      <td>I do not want pizza I want my oscar</td>\n",
       "      <td>I do not want pizza I want my oscar</td>\n",
       "      <td>funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>slight</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name                                           text_ocr  \\\n",
       "0  image_4112.jpg  YOU HAVE NEVER SEEN TITANIC?!? RU SRS? quickme...   \n",
       "1  image_3710.jpg  SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...   \n",
       "2  image_3739.jpg                 spiderman homecoming looks amazing   \n",
       "3    image_62.jpg  THANOS GETS ALL INFINITY STONES AT THE END OF ...   \n",
       "4  image_5891.jpg                I do not want pizza I want my oscar   \n",
       "\n",
       "                                      text_corrected      humour  \\\n",
       "0  YOU HAVE NEVER SEEN TITANIC?!? R U SRS? quickm...  very_funny   \n",
       "1  SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...  very_funny   \n",
       "2                 spiderman homecoming looks amazing  very_funny   \n",
       "3  THANOS GETS ALL INFINITY STONES AT THE END OF ...  very_funny   \n",
       "4                I do not want pizza I want my oscar       funny   \n",
       "\n",
       "           sarcasm       offensive      motivational overall_sentiment  label  \\\n",
       "0          general          slight  not_motivational          positive      1   \n",
       "1  twisted_meaning  very_offensive      motivational          positive      2   \n",
       "2          general   not_offensive  not_motivational          positive      0   \n",
       "3          general   not_offensive  not_motivational          positive      0   \n",
       "4    not_sarcastic          slight  not_motivational           neutral      1   \n",
       "\n",
       "   kfold  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../memotion_dataset_7k/folds.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99f860ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(fold) -> Tuple[DataLoader]:\n",
    "    df = pd.read_csv('../memotion_dataset_7k/folds.csv')\n",
    "    train_df = df[df['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = df[df['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = MemotionDataset(df=train_df)\n",
    "    valid_dataset = MemotionDataset(df=valid_df)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=Config.train_bs, shuffle=True)\n",
    "    valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=Config.valid_bs, shuffle=False)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da9a7398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 23.9 ms, total: 152 ms\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, valid = prepare_dataloaders(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "654975dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "### Fold [1/5]\n",
      "###############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jvwbyc3d) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FOLD-1|MODEL-google/vit-base-patch16-224+sentence-transformers/all-mpnet-base-v2</strong> at: <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/jvwbyc3d' target=\"_blank\">https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/jvwbyc3d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230330_232739-jvwbyc3d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jvwbyc3d). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6564c49dd34313a28cf8871f20be69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016752754866683973, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/aneeshaparajit/Desktop/reddit-multimodal-analysis/notebooks/wandb/run-20230330_232904-25172ss2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/25172ss2' target=\"_blank\">FOLD-1|MODEL-google/vit-base-patch16-224+sentence-transformers/all-mpnet-base-v2</a></strong> to <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis' target=\"_blank\">https://wandb.ai/aaparajit02/multimodal-sentiment-analysis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/25172ss2' target=\"_blank\">https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/25172ss2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224 were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t########## EPOCH [1/50] ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) :   0%|                                         | 0/234 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1646951978.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/1646951978.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3488894233.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_training</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/3488894233.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3816015336.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">41</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_one_epoch</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/3816015336.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torchmetrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metric.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">264</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._enable_grad = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># allow grads for batch computation</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">262 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reset()                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">263 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.update(*args, **kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>264 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_cache = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute()                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 │   │   # restore context</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">267 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> attr, val <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> cache.items():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torchmetrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metric.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">440</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapped_func</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">437 │   │   │   │   </span>should_sync=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._to_sync,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">438 │   │   │   │   </span>should_unsync=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._should_unsync,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">439 │   │   │   </span>):                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>440 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>value = compute(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">441 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._computed = _squeeze_if_scalar(value)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">442 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">443 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._computed                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torchmetrics/classification/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">auroc.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">175</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"You have to have determined mode.\"</span>)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   </span>preds = dim_zero_cat(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preds)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   </span>target = dim_zero_cat(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.target)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>175 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _auroc_compute(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 │   │   │   </span>preds,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   │   </span>target,                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mode,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torchmetrics/functional/classifica</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tion/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">auroc.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">135</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_auroc_compute</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> mode != DataType.BINARY:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> num_classes <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>135 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Detected input to `multiclass` but you did not provide</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> average == AverageMethod.WEIGHTED <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(torch.unique(target)) &lt; num_cla   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   │   │   │   # If one or more classes has 0 observations, we should exclude them, as </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   │   │   </span>target_bool_mat = torch.zeros((<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(target), num_classes), dtype=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span>, de   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Detected input to `multiclass` but you did not provide `num_classes` argument\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/\u001b[0m\u001b[1;33m1646951978.py\u001b[0m:\u001b[94m19\u001b[0m in \u001b[92m<module>\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/1646951978.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/\u001b[0m\u001b[1;33m3488894233.py\u001b[0m:\u001b[94m20\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mrun_training\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/3488894233.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/\u001b[0m\u001b[1;33m3816015336.py\u001b[0m:\u001b[94m41\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mtrain_one_epoch\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_20575/3816015336.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torchmetrics/\u001b[0m\u001b[1;33mmetric.py\u001b[0m:\u001b[94m264\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._enable_grad = \u001b[94mTrue\u001b[0m  \u001b[2m# allow grads for batch computation\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.reset()                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m263 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.update(*args, **kwargs)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m264 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._forward_cache = \u001b[96mself\u001b[0m.compute()                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# restore context\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m267 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m attr, val \u001b[95min\u001b[0m cache.items():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torchmetrics/\u001b[0m\u001b[1;33mmetric.py\u001b[0m:\u001b[94m440\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mwrapped_func\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m437 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mshould_sync=\u001b[96mself\u001b[0m._to_sync,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m438 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mshould_unsync=\u001b[96mself\u001b[0m._should_unsync,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m439 \u001b[0m\u001b[2m│   │   │   \u001b[0m):                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m440 \u001b[2m│   │   │   │   \u001b[0mvalue = compute(*args, **kwargs)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m441 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._computed = _squeeze_if_scalar(value)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m442 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m443 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._computed                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torchmetrics/classification/\u001b[0m\u001b[1;33mauroc.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m175\u001b[0m in \u001b[92mcompute\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mYou have to have determined mode.\u001b[0m\u001b[33m\"\u001b[0m)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0mpreds = dim_zero_cat(\u001b[96mself\u001b[0m.preds)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   \u001b[0mtarget = dim_zero_cat(\u001b[96mself\u001b[0m.target)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m175 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _auroc_compute(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m176 \u001b[0m\u001b[2m│   │   │   \u001b[0mpreds,                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   │   \u001b[0mtarget,                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.mode,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torchmetrics/functional/classifica\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtion/\u001b[0m\u001b[1;33mauroc.py\u001b[0m:\u001b[94m135\u001b[0m in \u001b[92m_auroc_compute\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mode != DataType.BINARY:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m num_classes \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m135 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mDetected input to `multiclass` but you did not provide\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m average == AverageMethod.WEIGHTED \u001b[95mand\u001b[0m \u001b[96mlen\u001b[0m(torch.unique(target)) < num_cla   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# If one or more classes has 0 observations, we should exclude them, as \u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtarget_bool_mat = torch.zeros((\u001b[96mlen\u001b[0m(target), num_classes), dtype=\u001b[96mbool\u001b[0m, de   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mDetected input to `multiclass` but you did not provide `num_classes` argument\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(Config.num_folds):\n",
    "    print('#'*15)\n",
    "    print(f'### Fold [{fold+1}/{Config.num_folds}]')\n",
    "    print('#'*15)\n",
    "    \n",
    "    run = wandb.init(\n",
    "        project='multimodal-sentiment-analysis',\n",
    "        config={k:v for k, v in dict(vars(Config)).items() if '__' not in k},\n",
    "        name=f'FOLD-{fold+1}|MODEL-{Config.backbone}', \n",
    "        group=f'FOLD-{fold+1}|MODEL-{Config.backbone}'\n",
    "    )\n",
    "    \n",
    "    trainloader, validloader = prepare_dataloaders(fold=fold)\n",
    "    \n",
    "    model = MemotionModel().to(Config.device)\n",
    "    optimizer = get_optimizer(model=model)\n",
    "    scheduler = get_scheduler(optimizer=optimizer)\n",
    "    \n",
    "    model, history = run_training(model=model, optimizer=optimizer, \n",
    "                                  trainloader=trainloader, validloader=validloader, \n",
    "                                  run=run, fold=fold, scheduler=scheduler)\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
