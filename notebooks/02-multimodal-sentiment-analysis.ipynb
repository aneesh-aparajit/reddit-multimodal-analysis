{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95cb3c8",
   "metadata": {},
   "source": [
    "# Multimodal Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efaca149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: aneesh-aparajit\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from colorama import Back, Fore, Style\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import AUROC, Accuracy, F1Score, Precision, Recall\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "c_ = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -a \"aneesh-aparajit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf227ea",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016dae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 101\n",
    "    debug = False  # set debug=False for Full Training\n",
    "    exp_name = \"vit/sbert\"\n",
    "    model_name = \"vit-sbert-multimodal\"\n",
    "    backbone = \"google/vit-base-patch16-224+sentence-transformers/all-mpnet-base-v2\"\n",
    "    tokenizer = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    image_encoder = \"google/vit-base-patch16-224\"\n",
    "    train_bs = 24\n",
    "    valid_bs = 48\n",
    "    img_size = [224, 224]\n",
    "    max_len = 128\n",
    "    epochs = 50\n",
    "    competition = \"memotions-7k\"\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer     = 'Adam'\n",
    "    learning_rate = 3e-4\n",
    "    rho           = 0.9\n",
    "    eps           = 1e-6\n",
    "    lr_decay      = 0\n",
    "    betas         = (0.9, 0.999)\n",
    "    momentum      = 0\n",
    "    alpha         = 0.99\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    weight_decay  = 1e-6\n",
    "\n",
    "    # Config\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    num_folds     = 5\n",
    "    num_classes   = 3\n",
    "\n",
    "    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f7b81",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886a7519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SEEDED <<<\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(\">>> SEEDED <<<\")\n",
    "\n",
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b0a16",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "## Get Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc5b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model: nn.Module):\n",
    "    \"\"\"\n",
    "    Returns the optimizer based on the Config files.\n",
    "    \"\"\"\n",
    "    if Config.optimizer == \"Adadelta\":\n",
    "        optimizer = optim.Adadelta(\n",
    "            model.parameters(), lr=Config.learning_rate, rho=Config.rho, eps=Config.eps\n",
    "        )\n",
    "    elif Config.optimizer == \"Adagrad\":\n",
    "        optimizer = optim.Adagrad(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            lr_decay=Config.lr_decay,\n",
    "            weight_decay=Config.weight_decay,\n",
    "        )\n",
    "    elif Config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            betas=Config.betas,\n",
    "            eps=Config.eps,\n",
    "        )\n",
    "    elif Config.optimizer == \"RMSProp\":\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            alpha=Config.alpha,\n",
    "            eps=Config.eps,\n",
    "            weight_decay=Config.weight_decay,\n",
    "            momentum=Config.momentum,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"The optimizer {Config.optimizer} has not been implemented.\"\n",
    "        )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ceb6d1",
   "metadata": {},
   "source": [
    "## Get Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f448c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer: optim):\n",
    "    \"\"\"\n",
    "    A method which returns the required schedulers.\n",
    "        - Extracted from Awsaf's Kaggle.\n",
    "    \"\"\"\n",
    "    if Config.scheduler == \"CosineAnnealingLR\":\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer=optimizer, T_max=Config.T_max, eta_min=Config.min_lr\n",
    "        )\n",
    "    elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer=optimizer, T_0=Config.T_0, eta_min=Config.eta_min\n",
    "        )\n",
    "    elif Config.scheduler == \"ReduceLROnPlateau\":\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=0.1,\n",
    "            patience=10,\n",
    "            threshold=0.0001,\n",
    "            min_lr=Config.min_lr,\n",
    "        )\n",
    "    elif Config.scheduler == \"ExponentialLR\":\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.85)\n",
    "    elif Config.scheduler is None:\n",
    "        scheduler = None\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"The Scheduler you have asked has not been implemented\"\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a0ccd1",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Create Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcfe4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds():\n",
    "    df = pd.read_csv('../memotion_dataset_7k/labels.csv')\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df['label'] = df['offensive']\n",
    "    df['label'] = np.where(df['label'] == 'hateful_offensive', 'very_offensive', df['label'])\n",
    "    \n",
    "    mskf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    df['kfold'] = -1\n",
    "    for fold, (train, valid) in enumerate(mskf.split(X=df, y=df['label'])):\n",
    "        df.loc[valid, 'kfold'] = fold\n",
    "    \n",
    "    df['label'] = df['label'].map({\n",
    "        'not_offensive': 0, \n",
    "        'slight': 1, \n",
    "        'very_offensive': 2\n",
    "    })\n",
    "\n",
    "    df.to_csv('../memotion_dataset_7k/folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05724f9b",
   "metadata": {},
   "source": [
    "## Sample Images\n",
    "![memes](../resources/memes-preview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95140a2",
   "metadata": {},
   "source": [
    "## Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b95db5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemotionDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(Config.tokenizer)\n",
    "        self.transforms = A.Compose([\n",
    "            A.Resize(height=Config.img_size[0], width=Config.img_size[1]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, ix: int) -> Dict[str, torch.Tensor]:\n",
    "        row = self.df.iloc[ix]\n",
    "\n",
    "        # Image\n",
    "        image_path = os.path.join('../memotion_dataset_7k/images', row['image_name'].lower())\n",
    "        img = np.array(Image.open(image_path).convert('RGB'))\n",
    "        img = self.transforms(image=img)['image']\n",
    "\n",
    "        # Text\n",
    "        text = str(row['text_corrected']).lower()\n",
    "        out = self.tokenizer(\n",
    "            text=text, \n",
    "            max_length=Config.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # __import__('pprint').pprint(out)\n",
    "\n",
    "        return  {\n",
    "            'image': img, \n",
    "            'input_ids': out['input_ids'].squeeze(),\n",
    "            'attention_mask': out['attention_mask'].squeeze(),\n",
    "            'label': torch.LongTensor([row['label']]).squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45711fdc",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8516575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = AutoModel.from_pretrained(Config.image_encoder)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encoder.forward(x)[\"pooler_output\"]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786dacb0",
   "metadata": {},
   "source": [
    "## Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b96665",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = AutoModel.from_pretrained(Config.tokenizer)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        x = self.encoder.forward(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return x[\"pooler_output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c1be4",
   "metadata": {},
   "source": [
    "## Memotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d52f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemotionModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.alpha_img = torch.randn(size=(1,), requires_grad=True)\n",
    "        self.alpha_txt = torch.randn(size=(1,), requires_grad=True)\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(\n",
    "        self, image: torch.Tensor, input_ids: torch.Tensor, attention_mask: torch.Tensor, label: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        img_out = self.image_encoder.forward(image)\n",
    "        txt_out = self.text_encoder.forward(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        wt_emb = self.alpha_txt * txt_out + self.alpha_img * img_out\n",
    "        x = self.fc1(self.dropout(wt_emb))\n",
    "        x = self.fc2(self.dropout(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f42d0b",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Training One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b648d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim,\n",
    "    dataloader: DataLoader,\n",
    "    scheduler=None,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    precision_metric = Precision(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    recall_metric = Recall(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    auroc_metric = AUROC(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    f1_metrics = F1Score(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"(train) \")\n",
    "    for step, batch in pbar:\n",
    "        batch = {k: v.to(Config.device) for k, v in batch.items()}\n",
    "        labels = batch[\"label\"]\n",
    "        yHat = model.forward(**batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(yHat, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.shape[0]\n",
    "        dataset_size += labels.shape[0]\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        out = torch.argmax(yHat, axis=1)\n",
    "        accuracy = accuracy_metric(out, labels)\n",
    "        precision = precision_metric(out, labels)\n",
    "        recall = recall_metric(out, labels)\n",
    "        auroc = auroc_metric(F.softmax(yHat, dim=1), labels)\n",
    "        f1 = f1_metrics(yHat, labels)\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train/loss\": epoch_loss,\n",
    "                \"train/accuracy\": accuracy,\n",
    "                \"train/precision\": precision,\n",
    "                \"train/recall\": recall,\n",
    "                \"train/auroc\": auroc,\n",
    "                \"train/f1\": f1,\n",
    "                \"train/current_lr\": current_lr,\n",
    "            },\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "        pbar.set_postfix(epoch_loss=f\"{epoch_loss:.5f}\", current_lr=f\"{current_lr:.5f}\")\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08615a",
   "metadata": {},
   "source": [
    "## Validating One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0036951",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "    model: nn.Module, dataloader: DataLoader\n",
    ") -> Tuple[float, dict]:\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    precision_metric = Precision(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    recall_metric = Recall(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    auroc_metric = AUROC(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    f1_metrics = F1Score(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "\n",
    "    val_scores = defaultdict(list)\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"(valid) \")\n",
    "    for step, batch in pbar:\n",
    "        batch = {k: v.to(Config.device) for k, v in batch.items()}\n",
    "        labels = batch[\"label\"]\n",
    "        yHat = model.forward(**batch)\n",
    "\n",
    "        loss = criterion(yHat, labels)\n",
    "\n",
    "        running_loss += loss.item() * labels.shape[0]\n",
    "        dataset_size += labels.shape[0]\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        out = torch.argmax(yHat, axis=1)\n",
    "        accuracy = accuracy_metric(out, labels)\n",
    "        precision = precision_metric(out, labels)\n",
    "        recall = recall_metric(out, labels)\n",
    "        auroc = auroc_metric(F.softmax(yHat, dim=1), labels)\n",
    "        f1 = f1_metrics(yHat, labels)\n",
    "\n",
    "        val_scores[\"accuracy\"].append(accuracy)\n",
    "        val_scores[\"precision\"].append(precision)\n",
    "        val_scores[\"recall\"].append(recall)\n",
    "        val_scores[\"auroc\"].append(auroc)\n",
    "        val_scores[\"f1\"].append(f1)\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"valid/loss\": epoch_loss,\n",
    "                \"valid/accuracy\": accuracy,\n",
    "                \"valid/precision\": precision,\n",
    "                \"valid/recall\": recall,\n",
    "                \"valid/auroc\": auroc,\n",
    "                \"valid/f1\": f1,\n",
    "            },\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "    return epoch_loss, val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5c782",
   "metadata": {},
   "source": [
    "## Train one Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8954cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim,\n",
    "    trainloader: DataLoader,\n",
    "    validloader: DataLoader,\n",
    "    run: wandb,\n",
    "    fold: int,\n",
    "    scheduler: lr_scheduler = None,\n",
    ") -> Tuple[nn.Module, defaultdict]:\n",
    "    wandb.watch(models=[model], log_freq=100)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "    best_epoch = -1\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "        gc.collect()\n",
    "        print(f\"\\t\\t\\t\\t########## EPOCH [{epoch+1}/{Config.epochs}] ##########\")\n",
    "        train_loss = train_one_epoch(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            dataloader=trainloader,\n",
    "        )\n",
    "        valid_loss, valid_scores = validate_one_epoch(\n",
    "            model=model, dataloader=validloader\n",
    "        )\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train/epoch/loss\": train_loss,\n",
    "                \"valid/epoch/loss\": valid_loss,\n",
    "                \"valid/epoch/accuracy\": np.mean(valid_scores[\"accuracy\"]),\n",
    "                \"valid/epoch/precision\": np.mean(valid_scores[\"precision\"]),\n",
    "                \"valid/epoch/recall\": np.mean(valid_scores[\"recall\"]),\n",
    "                \"valid/epoch/auroc\": np.mean(valid_scores[\"auroc\"]),\n",
    "                \"valid/epoch/f1\": np.mean(valid_scores[\"f1\"]),\n",
    "                \"current_lr\": optimizer.param_groups[0][\"lr\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        history[\"accuracy\"].append(np.mean(valid_scores[\"accuracy\"]))\n",
    "        history[\"precision\"].append(np.mean(valid_scores[\"precision\"]))\n",
    "        history[\"recall\"].append(np.mean(valid_scores[\"recall\"]))\n",
    "        history[\"auroc\"].append(np.mean(valid_scores[\"auroc\"]))\n",
    "        history[\"f1\"].append(np.mean(valid_scores[\"f1\"]))\n",
    "\n",
    "        print(\n",
    "            f'Valid Accuracy: {np.mean(valid_scores[\"accuracy\"]):.5f} | Valid Loss: {valid_loss:.5f}'\n",
    "        )\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            print(\n",
    "                f\"{c_}Validation Score Improved from {best_loss:.5f} to {valid_loss:.5f}\"\n",
    "            )\n",
    "            best_epoch = epoch + 1\n",
    "            best_loss = valid_loss\n",
    "            run.summary[\"Best Loss\"] = best_loss\n",
    "            run.summary[\"Best Epoch\"] = best_epoch\n",
    "            run.summary[\"Best Accuracy\"] = np.mean(valid_scores[\"accuracy\"])\n",
    "            run.summary[\"Best Precision\"] = np.mean(valid_scores[\"precision\"])\n",
    "            run.summary[\"Best Recall\"] = np.mean(valid_scores[\"recall\"])\n",
    "            run.summary[\"Best AUROC\"] = np.mean(valid_scores[\"auroc\"])\n",
    "            run.summary[\"Best F1 Score\"] = np.mean(valid_scores[\"f1\"])\n",
    "\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"../artifacts/models/best/best_epoch-{fold:02d}.bin\"\n",
    "            torch.save(obj=best_model_wts, f=PATH)\n",
    "            wandb.save(PATH)\n",
    "            print(f\"MODEL SAVED!{sr_}\")\n",
    "\n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"../artifacts/models/last/last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(last_model_wts, PATH)\n",
    "\n",
    "    model.load_state_dict(best_model_wts, strict=True)\n",
    "    torch.save(history, f=f\"../artifacts/history/fold-{fold:02d}.pth\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e8147",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b102846c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_4112.jpg</td>\n",
       "      <td>YOU HAVE NEVER SEEN TITANIC?!? RU SRS? quickme...</td>\n",
       "      <td>YOU HAVE NEVER SEEN TITANIC?!? R U SRS? quickm...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>slight</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_3710.jpg</td>\n",
       "      <td>SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...</td>\n",
       "      <td>SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_3739.jpg</td>\n",
       "      <td>spiderman homecoming looks amazing</td>\n",
       "      <td>spiderman homecoming looks amazing</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_62.jpg</td>\n",
       "      <td>THANOS GETS ALL INFINITY STONES AT THE END OF ...</td>\n",
       "      <td>THANOS GETS ALL INFINITY STONES AT THE END OF ...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_5891.jpg</td>\n",
       "      <td>I do not want pizza I want my oscar</td>\n",
       "      <td>I do not want pizza I want my oscar</td>\n",
       "      <td>funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>slight</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name                                           text_ocr  \\\n",
       "0  image_4112.jpg  YOU HAVE NEVER SEEN TITANIC?!? RU SRS? quickme...   \n",
       "1  image_3710.jpg  SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...   \n",
       "2  image_3739.jpg                 spiderman homecoming looks amazing   \n",
       "3    image_62.jpg  THANOS GETS ALL INFINITY STONES AT THE END OF ...   \n",
       "4  image_5891.jpg                I do not want pizza I want my oscar   \n",
       "\n",
       "                                      text_corrected      humour  \\\n",
       "0  YOU HAVE NEVER SEEN TITANIC?!? R U SRS? quickm...  very_funny   \n",
       "1  SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...  very_funny   \n",
       "2                 spiderman homecoming looks amazing  very_funny   \n",
       "3  THANOS GETS ALL INFINITY STONES AT THE END OF ...  very_funny   \n",
       "4                I do not want pizza I want my oscar       funny   \n",
       "\n",
       "           sarcasm       offensive      motivational overall_sentiment  label  \\\n",
       "0          general          slight  not_motivational          positive      1   \n",
       "1  twisted_meaning  very_offensive      motivational          positive      2   \n",
       "2          general   not_offensive  not_motivational          positive      0   \n",
       "3          general   not_offensive  not_motivational          positive      0   \n",
       "4    not_sarcastic          slight  not_motivational           neutral      1   \n",
       "\n",
       "   kfold  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../memotion_dataset_7k/folds.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e9db4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(fold) -> Tuple[DataLoader]:\n",
    "    df = pd.read_csv('../memotion_dataset_7k/folds.csv')\n",
    "    train_df = df[df['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = df[df['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = MemotionDataset(df=train_df)\n",
    "    valid_dataset = MemotionDataset(df=valid_df)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=Config.train_bs, shuffle=True)\n",
    "    valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=Config.valid_bs, shuffle=False)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38831870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.7 ms, sys: 17.5 ms, total: 112 ms\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, valid = prepare_dataloaders(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110427c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "### Fold [1/5]\n",
      "###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maaparajit02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/aneeshaparajit/Desktop/reddit-multimodal-analysis/notebooks/wandb/run-20230330_234026-yyt3doz8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/yyt3doz8' target=\"_blank\">FOLD-1|MODEL-google/vit-base-patch16-224+sentence-transformers/all-mpnet-base-v2</a></strong> to <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis' target=\"_blank\">https://wandb.ai/aaparajit02/multimodal-sentiment-analysis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/yyt3doz8' target=\"_blank\">https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/yyt3doz8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224 were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t########## EPOCH [1/50] ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) :  33%|███████████████████████████▋                                                       | 78/234 [19:35<42:25, 16.32s/it, current_lr=0.00030, epoch_loss=1.09411]"
     ]
    }
   ],
   "source": [
    "for fold in range(Config.num_folds):\n",
    "    print('#'*15)\n",
    "    print(f'### Fold [{fold+1}/{Config.num_folds}]')\n",
    "    print('#'*15)\n",
    "    \n",
    "    run = wandb.init(\n",
    "        project='multimodal-sentiment-analysis',\n",
    "        config={k:v for k, v in dict(vars(Config)).items() if '__' not in k},\n",
    "        name=f'FOLD-{fold+1}|MODEL-{Config.backbone}', \n",
    "        group=f'FOLD-{fold+1}|MODEL-{Config.backbone}'\n",
    "    )\n",
    "    \n",
    "    trainloader, validloader = prepare_dataloaders(fold=fold)\n",
    "    \n",
    "    model = MemotionModel().to(Config.device)\n",
    "    optimizer = get_optimizer(model=model)\n",
    "    scheduler = get_scheduler(optimizer=optimizer)\n",
    "    \n",
    "    model, history = run_training(model=model, optimizer=optimizer, \n",
    "                                  trainloader=trainloader, validloader=validloader, \n",
    "                                  run=run, fold=fold, scheduler=scheduler)\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
