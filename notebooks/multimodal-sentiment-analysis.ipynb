{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef9af09",
   "metadata": {},
   "source": [
    "# Multimodal Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c51c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: aneesh-aparajit\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from colorama import Back, Fore, Style\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import AUROC, Accuracy, F1Score, Precision, Recall\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "c_ = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -a \"aneesh-aparajit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d001a2",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f377f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 101\n",
    "    debug = False  # set debug=False for Full Training\n",
    "    exp_name = \"vit/sbert\"\n",
    "    model_name = \"vit-sbert-multimodal\"\n",
    "    backbone = \"google/vit-base-patch16-224+sentence-transformers/all-mpnet-base-v2\"\n",
    "    tokenizer = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    image_encoder = \"google/vit-base-patch16-224\"\n",
    "    train_bs = 24\n",
    "    valid_bs = 48\n",
    "    img_size = [224, 224]\n",
    "    max_len = 128\n",
    "    epochs = 50\n",
    "    competition = \"memotions-7k\"\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer     = 'Adam'\n",
    "    learning_rate = 3e-4\n",
    "    rho           = 0.9\n",
    "    eps           = 1e-6\n",
    "    lr_decay      = 0\n",
    "    betas         = (0.9, 0.999)\n",
    "    momentum      = 0\n",
    "    alpha         = 0.99\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    weight_decay  = 1e-6\n",
    "\n",
    "    # Config\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    num_folds     = 5\n",
    "    num_classes   = 3\n",
    "\n",
    "    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be16f9",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3eee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SEEDED <<<\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(\">>> SEEDED <<<\")\n",
    "\n",
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5f3f9",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "## Get Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b93d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model: nn.Module):\n",
    "    \"\"\"\n",
    "    Returns the optimizer based on the Config files.\n",
    "    \"\"\"\n",
    "    if Config.optimizer == \"Adadelta\":\n",
    "        optimizer = optim.Adadelta(\n",
    "            model.parameters(), lr=Config.learning_rate, rho=Config.rho, eps=Config.eps\n",
    "        )\n",
    "    elif Config.optimizer == \"Adagrad\":\n",
    "        optimizer = optim.Adagrad(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            lr_decay=Config.lr_decay,\n",
    "            weight_decay=Config.weight_decay,\n",
    "        )\n",
    "    elif Config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            betas=Config.betas,\n",
    "            eps=Config.eps,\n",
    "        )\n",
    "    elif Config.optimizer == \"RMSProp\":\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            alpha=Config.alpha,\n",
    "            eps=Config.eps,\n",
    "            weight_decay=Config.weight_decay,\n",
    "            momentum=Config.momentum,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"The optimizer {Config.optimizer} has not been implemented.\"\n",
    "        )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81254bba",
   "metadata": {},
   "source": [
    "## Get Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe3e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer: optim):\n",
    "    \"\"\"\n",
    "    A method which returns the required schedulers.\n",
    "        - Extracted from Awsaf's Kaggle.\n",
    "    \"\"\"\n",
    "    if Config.scheduler == \"CosineAnnealingLR\":\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer=optimizer, T_max=Config.T_max, eta_min=Config.min_lr\n",
    "        )\n",
    "    elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer=optimizer, T_0=Config.T_0, eta_min=Config.eta_min\n",
    "        )\n",
    "    elif Config.scheduler == \"ReduceLROnPlateau\":\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=0.1,\n",
    "            patience=10,\n",
    "            threshold=0.0001,\n",
    "            min_lr=Config.min_lr,\n",
    "        )\n",
    "    elif Config.scheduler == \"ExponentialLR\":\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.85)\n",
    "    elif Config.scheduler is None:\n",
    "        scheduler = None\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"The Scheduler you have asked has not been implemented\"\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fbfcc8",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Create Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13773fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds():\n",
    "    df = pd.read_csv('../memotion_dataset_7k/labels.csv')\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df['label'] = df['offensive']\n",
    "    df['label'] = np.where(df['label'] == 'hateful_offensive', 'very_offensive', df['label'])\n",
    "    \n",
    "    mskf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    df['kfold'] = -1\n",
    "    for fold, (train, valid) in enumerate(mskf.split(X=df, y=df['label'])):\n",
    "        df.loc[valid, 'kfold'] = fold\n",
    "    \n",
    "    df['label'] = df['label'].map({\n",
    "        'not_offensive': 0, \n",
    "        'slight': 1, \n",
    "        'very_offensive': 2\n",
    "    })\n",
    "\n",
    "    df.to_csv('../memotion_dataset_7k/folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4a0dd",
   "metadata": {},
   "source": [
    "## Sample Images\n",
    "![memes](../resources/memes-preview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f135ff9a",
   "metadata": {},
   "source": [
    "## Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad571c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemotionDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(Config.tokenizer)\n",
    "        self.transforms = A.Compose([\n",
    "            A.Resize(height=Config.img_size[0], width=Config.img_size[1]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, ix: int) -> Dict[str, torch.Tensor]:\n",
    "        row = self.df.iloc[ix]\n",
    "\n",
    "        # Image\n",
    "        image_path = os.path.join('../memotion_dataset_7k/images', row['image_name'].lower())\n",
    "        img = np.array(Image.open(image_path).convert('RGB'))\n",
    "        img = self.transforms(image=img)['image']\n",
    "\n",
    "        # Text\n",
    "        text = str(row['text_corrected']).lower()\n",
    "        out = self.tokenizer(\n",
    "            text=text, \n",
    "            max_length=Config.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # __import__('pprint').pprint(out)\n",
    "\n",
    "        return  {\n",
    "            'image': img, \n",
    "            'input_ids': out['input_ids'].squeeze(),\n",
    "            'attention_mask': out['attention_mask'].squeeze(),\n",
    "            'label': torch.LongTensor([row['label']]).squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde6e519",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53ed4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = AutoModel.from_pretrained(Config.image_encoder)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encoder.forward(x)[\"pooler_output\"]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6d210",
   "metadata": {},
   "source": [
    "## Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265234ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = AutoModel.from_pretrained(Config.tokenizer)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        x = self.encoder.forward(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return x[\"pooler_output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182fe93",
   "metadata": {},
   "source": [
    "## Memotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f92790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemotionModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.alpha_img = torch.randn(size=(1,), requires_grad=True)\n",
    "        self.alpha_txt = torch.randn(size=(1,), requires_grad=True)\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(\n",
    "        self, image: torch.Tensor, input_ids: torch.Tensor, attention_mask: torch.Tensor, label: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        img_out = self.image_encoder.forward(image)\n",
    "        txt_out = self.text_encoder.forward(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        wt_emb = self.alpha_txt * txt_out + self.alpha_img * img_out\n",
    "        x = self.fc1(self.dropout(wt_emb))\n",
    "        x = self.fc2(self.dropout(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f44f3c",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Training One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eedda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim,\n",
    "    dataloader: DataLoader,\n",
    "    scheduler=None,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    precision_metric = Precision(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    recall_metric = Recall(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    auroc_metric = AUROC(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    f1_metrics = F1Score(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"(train) \")\n",
    "    for step, batch in pbar:\n",
    "        batch = {k: v.to(Config.device) for k, v in batch.items()}\n",
    "        labels = batch[\"label\"]\n",
    "        yHat = model.forward(**batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(yHat, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.shape[0]\n",
    "        dataset_size += labels.shape[0]\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        out = torch.argmax(yHat, axis=1)\n",
    "        accuracy = accuracy_metric(out, labels)\n",
    "        precision = precision_metric(out, labels)\n",
    "        recall = recall_metric(out, labels)\n",
    "        auroc = auroc_metric(F.softmax(yHat, dim=1), labels)\n",
    "        f1 = f1_metrics(yHat, labels)\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train/loss\": epoch_loss,\n",
    "                \"train/accuracy\": accuracy,\n",
    "                \"train/precision\": precision,\n",
    "                \"train/recall\": recall,\n",
    "                \"train/auroc\": auroc,\n",
    "                \"train/f1\": f1,\n",
    "                \"train/current_lr\": current_lr,\n",
    "            },\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "        pbar.set_postfix(epoch_loss=f\"{epoch_loss:.5f}\", current_lr=f\"{current_lr:.5f}\")\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c042f57",
   "metadata": {},
   "source": [
    "## Validating One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eaafa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "    model: nn.Module, dataloader: DataLoader\n",
    ") -> Tuple[float, dict]:\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    precision_metric = Precision(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    recall_metric = Recall(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    auroc_metric = AUROC(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "    f1_metrics = F1Score(task=\"multiclass\", num_classes=Config.num_classes)\n",
    "\n",
    "    val_scores = defaultdict(list)\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"(valid) \")\n",
    "    for step, batch in pbar:\n",
    "        batch = {k: v.to(Config.device) for k, v in batch.items()}\n",
    "        labels = batch[\"label\"]\n",
    "        yHat = model.forward(**batch)\n",
    "\n",
    "        loss = criterion(yHat, labels)\n",
    "\n",
    "        running_loss += loss.item() * labels.shape[0]\n",
    "        dataset_size += labels.shape[0]\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        out = torch.argmax(yHat, axis=1)\n",
    "        accuracy = accuracy_metric(out, labels)\n",
    "        precision = precision_metric(out, labels)\n",
    "        recall = recall_metric(out, labels)\n",
    "        auroc = auroc_metric(F.softmax(yHat, dim=1), labels)\n",
    "        f1 = f1_metrics(yHat, labels)\n",
    "\n",
    "        val_scores[\"accuracy\"].append(accuracy)\n",
    "        val_scores[\"precision\"].append(precision)\n",
    "        val_scores[\"recall\"].append(recall)\n",
    "        val_scores[\"auroc\"].append(auroc)\n",
    "        val_scores[\"f1\"].append(f1)\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"valid/loss\": epoch_loss,\n",
    "                \"valid/accuracy\": accuracy,\n",
    "                \"valid/precision\": precision,\n",
    "                \"valid/recall\": recall,\n",
    "                \"valid/auroc\": auroc,\n",
    "                \"valid/f1\": f1,\n",
    "            },\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "    return epoch_loss, val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f194be",
   "metadata": {},
   "source": [
    "## Train one Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70bf62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim,\n",
    "    trainloader: DataLoader,\n",
    "    validloader: DataLoader,\n",
    "    run: wandb,\n",
    "    fold: int,\n",
    "    scheduler: lr_scheduler = None,\n",
    ") -> Tuple[nn.Module, defaultdict]:\n",
    "    wandb.watch(models=[model], log_freq=100)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "    best_epoch = -1\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "        gc.collect()\n",
    "        print(f\"\\t\\t\\t\\t########## EPOCH [{epoch+1}/{Config.epochs}] ##########\")\n",
    "        train_loss = train_one_epoch(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            dataloader=trainloader,\n",
    "        )\n",
    "        valid_loss, valid_scores = validate_one_epoch(\n",
    "            model=model, dataloader=validloader\n",
    "        )\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train/epoch/loss\": train_loss,\n",
    "                \"valid/epoch/loss\": valid_loss,\n",
    "                \"valid/epoch/accuracy\": np.mean(valid_scores[\"accuracy\"]),\n",
    "                \"valid/epoch/precision\": np.mean(valid_scores[\"precision\"]),\n",
    "                \"valid/epoch/recall\": np.mean(valid_scores[\"recall\"]),\n",
    "                \"valid/epoch/auroc\": np.mean(valid_scores[\"auroc\"]),\n",
    "                \"valid/epoch/f1\": np.mean(valid_scores[\"f1\"]),\n",
    "                \"current_lr\": optimizer.param_groups[0][\"lr\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        history[\"accuracy\"].append(np.mean(valid_scores[\"accuracy\"]))\n",
    "        history[\"precision\"].append(np.mean(valid_scores[\"precision\"]))\n",
    "        history[\"recall\"].append(np.mean(valid_scores[\"recall\"]))\n",
    "        history[\"auroc\"].append(np.mean(valid_scores[\"auroc\"]))\n",
    "        history[\"f1\"].append(np.mean(valid_scores[\"f1\"]))\n",
    "\n",
    "        print(\n",
    "            f'Valid Accuracy: {np.mean(valid_scores[\"accuracy\"]):.5f} | Valid Loss: {valid_loss:.5f}'\n",
    "        )\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            print(\n",
    "                f\"{c_}Validation Score Improved from {best_loss:.5f} to {valid_loss:.5f}\"\n",
    "            )\n",
    "            best_epoch = epoch + 1\n",
    "            best_loss = valid_loss\n",
    "            run.summary[\"Best Loss\"] = best_loss\n",
    "            run.summary[\"Best Epoch\"] = best_epoch\n",
    "            run.summary[\"Best Accuracy\"] = np.mean(valid_scores[\"accuracy\"])\n",
    "            run.summary[\"Best Precision\"] = np.mean(valid_scores[\"precision\"])\n",
    "            run.summary[\"Best Recall\"] = np.mean(valid_scores[\"recall\"])\n",
    "            run.summary[\"Best AUROC\"] = np.mean(valid_scores[\"auroc\"])\n",
    "            run.summary[\"Best F1 Score\"] = np.mean(valid_scores[\"f1\"])\n",
    "\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"../artifacts/models/best/best_epoch-{fold:02d}.bin\"\n",
    "            torch.save(obj=best_model_wts, f=PATH)\n",
    "            wandb.save(PATH)\n",
    "            print(f\"MODEL SAVED!{sr_}\")\n",
    "\n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"../artifacts/models/last/last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(last_model_wts, PATH)\n",
    "\n",
    "    model.load_state_dict(best_model_wts, strict=True)\n",
    "    torch.save(history, f=f\"../artifacts/history/fold-{fold:02d}.pth\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea0c36",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a92a58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_4112.jpg</td>\n",
       "      <td>YOU HAVE NEVER SEEN TITANIC?!? RU SRS? quickme...</td>\n",
       "      <td>YOU HAVE NEVER SEEN TITANIC?!? R U SRS? quickm...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>slight</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_3710.jpg</td>\n",
       "      <td>SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...</td>\n",
       "      <td>SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_3739.jpg</td>\n",
       "      <td>spiderman homecoming looks amazing</td>\n",
       "      <td>spiderman homecoming looks amazing</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_62.jpg</td>\n",
       "      <td>THANOS GETS ALL INFINITY STONES AT THE END OF ...</td>\n",
       "      <td>THANOS GETS ALL INFINITY STONES AT THE END OF ...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_5891.jpg</td>\n",
       "      <td>I do not want pizza I want my oscar</td>\n",
       "      <td>I do not want pizza I want my oscar</td>\n",
       "      <td>funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>slight</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name                                           text_ocr  \\\n",
       "0  image_4112.jpg  YOU HAVE NEVER SEEN TITANIC?!? RU SRS? quickme...   \n",
       "1  image_3710.jpg  SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...   \n",
       "2  image_3739.jpg                 spiderman homecoming looks amazing   \n",
       "3    image_62.jpg  THANOS GETS ALL INFINITY STONES AT THE END OF ...   \n",
       "4  image_5891.jpg                I do not want pizza I want my oscar   \n",
       "\n",
       "                                      text_corrected      humour  \\\n",
       "0  YOU HAVE NEVER SEEN TITANIC?!? R U SRS? quickm...  very_funny   \n",
       "1  SAYS THEY'VE BEEN REBUILDING FOR 5 YEARS #SCOT...  very_funny   \n",
       "2                 spiderman homecoming looks amazing  very_funny   \n",
       "3  THANOS GETS ALL INFINITY STONES AT THE END OF ...  very_funny   \n",
       "4                I do not want pizza I want my oscar       funny   \n",
       "\n",
       "           sarcasm       offensive      motivational overall_sentiment  label  \\\n",
       "0          general          slight  not_motivational          positive      1   \n",
       "1  twisted_meaning  very_offensive      motivational          positive      2   \n",
       "2          general   not_offensive  not_motivational          positive      0   \n",
       "3          general   not_offensive  not_motivational          positive      0   \n",
       "4    not_sarcastic          slight  not_motivational           neutral      1   \n",
       "\n",
       "   kfold  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../memotion_dataset_7k/folds.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05b79b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(fold) -> Tuple[DataLoader]:\n",
    "    df = pd.read_csv('../memotion_dataset_7k/folds.csv')\n",
    "    train_df = df[df['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = df[df['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = MemotionDataset(df=train_df)\n",
    "    valid_dataset = MemotionDataset(df=valid_df)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=Config.train_bs, shuffle=True)\n",
    "    valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=Config.valid_bs, shuffle=False)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3875e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.7 ms, sys: 17.5 ms, total: 112 ms\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, valid = prepare_dataloaders(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20d4959",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "### Fold [1/5]\n",
      "###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maaparajit02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/aneeshaparajit/Desktop/reddit-multimodal-analysis/notebooks/wandb/run-20230330_234026-yyt3doz8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/yyt3doz8' target=\"_blank\">FOLD-1|MODEL-google/vit-base-patch16-224+sentence-transformers/all-mpnet-base-v2</a></strong> to <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis' target=\"_blank\">https://wandb.ai/aaparajit02/multimodal-sentiment-analysis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/yyt3doz8' target=\"_blank\">https://wandb.ai/aaparajit02/multimodal-sentiment-analysis/runs/yyt3doz8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224 were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t########## EPOCH [1/50] ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) :  36%|█████████████████████████████▊                                                     | 84/234 [21:29<38:23, 15.36s/it, current_lr=0.00030, epoch_loss=1.09292]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1646951978.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/1646951978.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3488894233.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_training</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/3488894233.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3816015336.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">26</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_one_epoch</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/3816015336.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/wandb/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wandb_torch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">282</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;lambda&gt;</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">280 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.log_tensor_stats(grad.data, name)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>282 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>handle = var.register_hook(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> grad: _callback(grad, log_track))                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">283 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._hook_handles[name] = handle                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">284 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> handle                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">285 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/\u001b[0m\u001b[1;33m1646951978.py\u001b[0m:\u001b[94m19\u001b[0m in \u001b[92m<module>\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/1646951978.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/\u001b[0m\u001b[1;33m3488894233.py\u001b[0m:\u001b[94m20\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mrun_training\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/3488894233.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/\u001b[0m\u001b[1;33m3816015336.py\u001b[0m:\u001b[94m26\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mtrain_one_epoch\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/9c/hg99j16578569gfzb3w5bzdh0000gn/T/ipykernel_21603/3816015336.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mbackward\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/aneeshaparajit/miniconda3/lib/python3.10/site-packages/wandb/\u001b[0m\u001b[1;33mwandb_torch.py\u001b[0m:\u001b[94m282\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m<lambda>\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m280 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.log_tensor_stats(grad.data, name)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m282 \u001b[2m│   │   \u001b[0mhandle = var.register_hook(\u001b[94mlambda\u001b[0m grad: _callback(grad, log_track))                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._hook_handles[name] = handle                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m284 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m handle                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m285 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n"
     ]
    }
   ],
   "source": [
    "for fold in range(Config.num_folds):\n",
    "    print('#'*15)\n",
    "    print(f'### Fold [{fold+1}/{Config.num_folds}]')\n",
    "    print('#'*15)\n",
    "    \n",
    "    run = wandb.init(\n",
    "        project='multimodal-sentiment-analysis',\n",
    "        config={k:v for k, v in dict(vars(Config)).items() if '__' not in k},\n",
    "        name=f'FOLD-{fold+1}|MODEL-{Config.backbone}', \n",
    "        group=f'FOLD-{fold+1}|MODEL-{Config.backbone}'\n",
    "    )\n",
    "    \n",
    "    trainloader, validloader = prepare_dataloaders(fold=fold)\n",
    "    \n",
    "    model = MemotionModel().to(Config.device)\n",
    "    optimizer = get_optimizer(model=model)\n",
    "    scheduler = get_scheduler(optimizer=optimizer)\n",
    "    \n",
    "    model, history = run_training(model=model, optimizer=optimizer, \n",
    "                                  trainloader=trainloader, validloader=validloader, \n",
    "                                  run=run, fold=fold, scheduler=scheduler)\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
